{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd\n",
    "from mxnet.gluon import nn, rnn\n",
    " \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "context = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we using Stanford's Large Movie Review Dataset available at this\n",
    "# link: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "def read_files(foldername):\n",
    "    import os\n",
    "    sentiments = []\n",
    "    filenames = os.listdir(os.curdir+ \"/\"+foldername)\n",
    "    for file in filenames:\n",
    "        with open(foldername+\"/\"+file,\"r\", encoding=\"utf8\") as pos_file:\n",
    "            data=pos_file.read().replace('\\n', '')\n",
    "            sentiments.append(data)\n",
    "    return sentiments\n",
    "    \n",
    "    \n",
    "foldername = \"aclImdb/train/pos/\"\n",
    "postive_sentiment = read_files(foldername)\n",
    "\n",
    "foldername = \"aclImdb/train/neg/\"\n",
    "negative_sentiment = read_files(foldername)\n",
    "\n",
    "positive_labels = [1 for _ in postive_sentiment]\n",
    "negative_labels = [0 for _ in negative_sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some string preprocessing\n",
    "def clean_str(string):  \n",
    "    remove_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(remove_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dict of word and their count in entrie dataset{word:count}\n",
    "\n",
    "word_counter = Counter()\n",
    "def create_count(sentiments):\n",
    "    for line in sentiments:\n",
    "        for word in (clean_str(line)).split():\n",
    "            if word not in word_counter.keys():               \n",
    "                word_counter[word] = 1\n",
    "            else:\n",
    "                word_counter[word] += 1\n",
    "\n",
    "#Assigns a unique a number for each word (sorted by descending order based on the frequency of occurrence)\n",
    "# and returns a word_dict\n",
    "def create_word_index():\n",
    "    idx = 1\n",
    "    word_dict = {}\n",
    "    for word in word_counter.most_common():\n",
    "        word_dict[word[0]] = idx\n",
    "        idx+=1\n",
    "    return word_dict\n",
    "    \n",
    "\n",
    "all_sentiments = postive_sentiment + negative_sentiment\n",
    "all_labels = positive_labels + negative_labels\n",
    "create_count(all_sentiments)\n",
    "word_dict = create_word_index()\n",
    "\n",
    "#create a reverse index from a number to the word \n",
    "idx2word = {v: k for k, v in word_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a encoded sentences. \n",
    "#Assigns the unique id from wordict to the words in the sentences\n",
    "def encoded_sentences(input_file,word_dict):\n",
    "    output_string = []\n",
    "    for line in input_file:\n",
    "        output_line = []\n",
    "        for word in (clean_str(line)).split():\n",
    "            if word in word_dict:\n",
    "                output_line.append(word_dict[word])\n",
    "        output_string.append(output_line)\n",
    "    return output_string\n",
    "\n",
    "def decode_sentences(input_file,word_dict):\n",
    "    output_string = []\n",
    "    for line in input_file:\n",
    "        output_line = ''\n",
    "        for idx in line:\n",
    "            output_line += idx2word[idx] + ' '\n",
    "        output_string.append(output_line)\n",
    "    return output_string\n",
    "\n",
    "#Pad the sequences to maxlen.\n",
    "#if sentences is greater than maxlen, truncates the sentences\n",
    "#if sentences is less the 500, pads with value 0 (most commonly occurrning word)\n",
    "def pad_sequences(sentences,maxlen=500,value=0):\n",
    "    \"\"\"\n",
    "    Pads all sentences to the same length. The length is defined by maxlen.\n",
    "    Returns padded sentences.\n",
    "    \"\"\"\n",
    "    padded_sentences = []\n",
    "    for sen in sentences:\n",
    "        new_sentence = []\n",
    "        if(len(sen) > maxlen):\n",
    "            new_sentence = sen[:maxlen]\n",
    "            padded_sentences.append(new_sentence)\n",
    "        else:\n",
    "            num_padding = maxlen - len(sen)\n",
    "            new_sentence = np.append(sen,[value] * num_padding)\n",
    "            padded_sentences.append(new_sentence)\n",
    "    return padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encodes the positive sentiment into sequence of number.\n",
    "positive_encoded = encoded_sentences(postive_sentiment,word_dict)\n",
    "negative_encoded = encoded_sentences(negative_sentiment,word_dict)\n",
    "\n",
    "all_encoded = positive_encoded + negative_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50000 #Here we set the total num of words to be tracked\n",
    "\n",
    "#Any word outside of the tracked range will be encoded with last position\n",
    "t_data = [np.array([i if i<(vocab_size-1) else (vocab_size-1) for i in s]) for s in all_encoded]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads Stanford's Global Vector for Word Representation (GloVe) embedding\n",
    "# We specifically used glove.42B.300d.zip available at this link:\n",
    "# https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "num_embed = 300 #This is the richness of the word attributes captured\n",
    "\n",
    "def load_glove_index(loc):\n",
    "    f = open(loc, encoding=\"utf8\")\n",
    "    embeddings_index = {}\n",
    "    \n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index\n",
    "\n",
    "def create_emb():\n",
    "    embedding_matrix = np.zeros((vocab_size, num_embed))\n",
    "    for word, i in word_dict.items():\n",
    "        if i >= vocab_size:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    embedding_matrix = nd.array(embedding_matrix).as_in_context(context)\n",
    "    return embedding_matrix\n",
    "\n",
    "embeddings_index = load_glove_index('glove.42B.300d.txt')\n",
    "embedding_matrix = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train+validation, test split\n",
    "X_train_val, X_test, y_train_val, y_test_set = train_test_split(t_data, all_labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validation split of data\n",
    "X_train, X_val, y_train, y_validation = train_test_split(X_train_val, y_train_val, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the minimum length is: 10\n",
      "the maximum length is: 2459\n",
      "the average length is: 230.51952\n"
     ]
    }
   ],
   "source": [
    "#statistics of sentences before padding\n",
    "min_len = min(map(len, t_data))\n",
    "max_len = max(map(len,t_data))\n",
    "avg_len = sum(map(len,t_data)) / len(t_data)\n",
    "print(\"the minimum length is:\",min_len)\n",
    "print(\"the maximum length is:\",max_len)\n",
    "print(\"the average length is:\",avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 500 #This set the max word length of each movie review\n",
    "\n",
    "#padding of sentences\n",
    "trn = nd.array(pad_sequences(X_train, maxlen=seq_len, value=0))\n",
    "val = nd.array(pad_sequences(X_val, maxlen=seq_len, value=0))\n",
    "test = nd.array(pad_sequences(X_test, maxlen=seq_len, value=0))\n",
    "y_trn = nd.array(y_train).as_in_context(context)\n",
    "y_val = nd.array(y_validation).as_in_context(context)\n",
    "y_test = nd.array(y_test_set).as_in_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_hidden = 64\n",
    "learning_rate = .001\n",
    "epochs = 10\n",
    "batch_size = 24\n",
    "\n",
    "\n",
    "model = mx.gluon.nn.Sequential()\n",
    "\n",
    "with model.name_scope():    \n",
    "    model.embed = mx.gluon.nn.Embedding(vocab_size, num_embed)\n",
    "    model.add(mx.gluon.rnn.LSTM(num_hidden, layout = 'NTC'))\n",
    "    model.add(mx.gluon.nn.Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(x,y,batch_size):\n",
    "    \n",
    "    acc = mx.metric.Accuracy()\n",
    "    \n",
    "    for i in range(x.shape[0] // batch_size):\n",
    "        data = x[i*batch_size:(i*batch_size + batch_size),]\n",
    "        target = y[i*batch_size:(i*batch_size + batch_size),]\n",
    "    \n",
    "        output = model(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        acc.update(preds=predictions, labels=target)\n",
    "    \n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[14:33:43] src/c_api/c_api_ndarray.cc:128: Check failed: ndinputs[i].ctx().dev_mask() == ctx.dev_mask() (1 vs. 2) All inputs must live on the same context. But the first argument is on gpu(0) while the 3-th argument is on cpu(0)\n\nStack trace returned 10 entries:\n[bt] (0) /usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f03f6eb3f0c]\n[bt] (1) /usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/libmxnet.so(_Z10SetContextPN5mxnet7ContextERKN4nnvm9NodeAttrsERKSt6vectorINS_7NDArrayESaIS7_EESB_RKS0_+0x37b) [0x7f03f7f0d43b]\n[bt] (2) /usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/libmxnet.so(_Z20ImperativeInvokeImplRKN5mxnet7ContextERKN4nnvm9NodeAttrsEPSt6vectorINS_7NDArrayESaIS8_EESB_+0x15e) [0x7f03f7f1226e]\n[bt] (3) /usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/libmxnet.so(MXImperativeInvoke+0x217) [0x7f03f7f12cd7]\n[bt] (4) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call_unix64+0x4c) [0x7f0427e73e20]\n[bt] (5) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call+0x2eb) [0x7f0427e7388b]\n[bt] (6) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(_ctypes_callproc+0x49a) [0x7f0427e6e01a]\n[bt] (7) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(+0x9fcb) [0x7f0427e61fcb]\n[bt] (8) /usr/bin/python3(PyObject_Call+0x47) [0x5b5da7]\n[bt] (9) /usr/bin/python3(PyEval_EvalFrameEx+0x4eb6) [0x528956]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0b38e81c2326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/gluon/nn/basic_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/gluon/rnn/rnn_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2h_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish_deferred_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gpu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/gluon/rnn/rnn_layer.py\u001b[0m in \u001b[0;36m_forward_gpu\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m    218\u001b[0m         rnn = ndarray.RNN(inputs, params, *states, state_size=self._hidden_size,\n\u001b[1;32m    219\u001b[0m                           \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dir\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                           p=self._dropout, state_outputs=True, mode=self._mode)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/ndarray.py\u001b[0m in \u001b[0;36mRNN\u001b[0;34m(data, parameters, state, state_cell, state_size, num_layers, bidirectional, mode, p, state_outputs, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         c_array(ctypes.c_char_p, [c_str(str(val)) for val in vals])))\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [14:33:43] src/c_api/c_api_ndarray.cc:128: Check failed: ndinputs[i].ctx().dev_mask() == ctx.dev_mask() (1 vs. 2) All inputs must live on the same context. But the first argument is on gpu(0) while the 3-th argument is on cpu(0)\n\nStack trace returned 10 entries:\n[bt] (0) /usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f03f6eb3f0c]\n[bt] (1) /usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/libmxnet.so(_Z10SetContextPN5mxnet7ContextERKN4nnvm9NodeAttrsERKSt6vectorINS_7NDArrayESaIS7_EESB_RKS0_+0x37b) [0x7f03f7f0d43b]\n[bt] (2) /usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/libmxnet.so(_Z20ImperativeInvokeImplRKN5mxnet7ContextERKN4nnvm9NodeAttrsEPSt6vectorINS_7NDArrayESaIS8_EESB_+0x15e) [0x7f03f7f1226e]\n[bt] (3) /usr/local/lib/python3.5/dist-packages/mxnet-0.11.0-py3.5.egg/mxnet/libmxnet.so(MXImperativeInvoke+0x217) [0x7f03f7f12cd7]\n[bt] (4) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call_unix64+0x4c) [0x7f0427e73e20]\n[bt] (5) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call+0x2eb) [0x7f0427e7388b]\n[bt] (6) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(_ctypes_callproc+0x49a) [0x7f0427e6e01a]\n[bt] (7) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(+0x9fcb) [0x7f0427e61fcb]\n[bt] (8) /usr/bin/python3(PyObject_Call+0x47) [0x5b5da7]\n[bt] (9) /usr/bin/python3(PyEval_EvalFrameEx+0x4eb6) [0x528956]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx=context)\n",
    "\n",
    "model.embed.weight.set_data(embedding_matrix.as_in_context(context))\n",
    "\n",
    "trainer = gluon.Trainer(model.collect_params(), 'sgd',\n",
    "                        {'learning_rate': learning_rate})\n",
    "\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()    \n",
    "\n",
    "for epoch in range(epochs):\n",
    "            \n",
    "    for b in range(trn.shape[0] // batch_size):\n",
    "        data = trn[b*batch_size:(b*batch_size + batch_size),]\n",
    "        target = y_trn[b*batch_size:(b*batch_size + batch_size),]\n",
    "        \n",
    "        data = data.as_in_context(context)\n",
    "        target = target.as_in_context(context)\n",
    "        \n",
    "        with autograd.record():\n",
    "            output = model(data)\n",
    "            L = softmax_cross_entropy(output, target)\n",
    "            L.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "            \n",
    "    test_accuracy = evaluate_accuracy(trn, y_trn, batch_size)\n",
    "    train_accuracy = evaluate_accuracy(test, y_test, batch_size)\n",
    "    print(\"Epoch %s. Train_acc %s, Test_acc %s\" %\n",
    "          (epoch, train_accuracy, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
